{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first run code from https://github.com/USC-Melady/Benchmarking_DL_MIMICIII to get the pre-processed files\n",
    "\n",
    "# import\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import datetime\n",
    "\n",
    "# root_path: where Benchmarking_DL_MIMICIII code is run/stored\n",
    "# res_path: where resulting data should be saved\n",
    "root_path = ... # to be filled\n",
    "res_path = ... # to be filled\n",
    "\n",
    "# load data\n",
    "header_mimic_input =  ['age',\n",
    "                 'heartrate_max','heartrate_min',\n",
    "                 'sysbp_max','sysbp_min',\n",
    "                 'tempc_max','tempc_min',\n",
    "                 'pao2fio2_vent_min',\n",
    "                 'urineoutput',\n",
    "                 'bun_min','bun_max',\n",
    "                 'wbc_min','wbc_max',\n",
    "                 'potassium_min','potassium_max',\n",
    "                 'sodium_min','sodium_max',\n",
    "                 'bicarbonate_min','bicarbonate_max',\n",
    "                 'bilirubin_min','bilirubin_max',\n",
    "                 'mingcs',\n",
    "                 'aids',\n",
    "                 'hem',\n",
    "                 'mets',\n",
    "                 'admissiontype']\n",
    "header_mimic_output =  ['hospital_mort',\n",
    "                 '1_day_mort',\n",
    "                 '2_day_mort',\n",
    "                 '3_day_mort',\n",
    "                 '30_day_mort',\n",
    "                 '1_year_mort',]\n",
    "\n",
    "# input file - non-series\n",
    "df_input = pd.read_csv(root_path + 'data/admdata_17f/24hrs/non_series/input.csv', header=None)\n",
    "df_input.to_csv('input_mimic.csv', header=header_mimic_input, index=False)\n",
    "df_input = pd.read_csv('input_mimic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get valid admissions\n",
    "data = np.load(root_path + 'data/admdata_17f/24hrs/DB_merged_24hrs.npy',allow_pickle=True)\n",
    "valid_aids = [t[0][-1] for t in data]\n",
    "print(len(valid_aids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use valid admissions to filter\n",
    "df = pd.read_csv(root_path + 'data/17features_first24h.csv')\n",
    "print(len(df))\n",
    "df = df[df['hadm_id'].isin(valid_aids)]\n",
    "print(len(df))\n",
    "df = df.drop_duplicates('subject_id')\n",
    "print(len(df))\n",
    "\n",
    "# drop columns\n",
    "df = df.drop(columns=['intime', 'outtime'])\n",
    "\n",
    "# check the columns\n",
    "df.loc[df['admissiontype'] == 'Medical', 'admissiontype'] = 0\n",
    "df.loc[df['admissiontype'] == 'ScheduledSurgical', 'admissiontype'] = 1\n",
    "df.loc[df['admissiontype'] == 'UnscheduledSurgical', 'admissiontype'] = 2\n",
    "\n",
    "# iterate over columns,\n",
    "for column in range(len(df.columns)):\n",
    "    # initialize new vector\n",
    "    curr_col = df[df.columns[column]]\n",
    "    # check if categorical\n",
    "    if (df.columns[column] == 'mingcs' or df.columns[column] == 'admissiontype'):\n",
    "        print(df.columns[column], curr_col.isnull().sum(),round(curr_col.mean()))\n",
    "        curr_col.fillna(round(curr_col.mean()),inplace=True) \n",
    "    elif (df.columns[column] == 'aids' or df.columns[column] == 'hem' or df.columns[column] == 'mets'): \n",
    "        print(df.columns[column], curr_col.isnull().sum())\n",
    "        curr_col.fillna(0,inplace=True) \n",
    "    else:\n",
    "        print(df.columns[column], curr_col.isnull().sum(),curr_col.mean())\n",
    "        curr_col.fillna(curr_col.mean(),inplace=True)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get gender info from PATIENTS.csv from MIMIC-III (change the path if it is stored somewhere else)\n",
    "data_gender = pd.read_csv(root_path + 'PATIENTS.csv')\n",
    "data_gender = data_gender[data_gender['SUBJECT_ID'].isin(df['subject_id'])][['SUBJECT_ID','GENDER']]\n",
    "data_gender = data_gender.rename(columns={\"SUBJECT_ID\": \"subject_id\", \"GENDER\": \"gender\"})\n",
    "print(len(data_gender))\n",
    "df = pd.merge(df, data_gender, on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get other infos from ADMISSIONS.csv from MIMIC-III (change the path if it is stored somewhere else)\n",
    "data_others = pd.read_csv(root_path + 'ADMISSIONS.csv')\n",
    "data_others = data_others[data_others['SUBJECT_ID'].isin(df['subject_id'])][['SUBJECT_ID','INSURANCE','RELIGION','MARITAL_STATUS','ETHNICITY']]\n",
    "data_others = data_others.rename(columns={\"SUBJECT_ID\": \"subject_id\", \n",
    "                                         \"INSURANCE\": \"insurance\",\n",
    "                                         \"RELIGION\": \"religion\",\n",
    "                                         \"MARITAL_STATUS\": \"marital_status\",\n",
    "                                         \"ETHNICITY\": \"ethnicity\"})\n",
    "data_others = data_others.drop_duplicates('subject_id')\n",
    "df = pd.merge(df, data_others, on='subject_id')\n",
    "\n",
    "# drop columns\n",
    "df = df.drop(columns=['subject_id', 'hadm_id', 'icustay_id'])\n",
    "\n",
    "# save the data\n",
    "df.to_csv(res_path + 'mimic_non_series.csv', index=False)\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction tasks\n",
    "df_output = pd.read_csv(root_path + 'data/admdata_17f/24hrs/non_series/output.csv', header=None)\n",
    "df_output.to_csv('output_mimic.csv', header=header_mimic_output, index=False)\n",
    "df_output = pd.read_csv('output_mimic.csv')\n",
    "print(len(df_output))\n",
    "\n",
    "# merge\n",
    "df = pd.concat([df, df_output], axis=1)\n",
    "\n",
    "# save the data\n",
    "df.to_csv(res_path + 'mimic_non_series.csv', index=False)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
